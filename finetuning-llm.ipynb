{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Select Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "TARGET_MODEL = \"distilbert/distilbert-base-uncased\"\n",
        "#TARGET_MODEL = \"microsoft/deberta-v3-large\"\n",
        "#TARGET_MODEL = \"microsoft/Phi-3-mini-128k-instruct\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718300643859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory settings\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT_DIR = Path(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Output/\")\n",
        "#OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "INPUT_DIR = Path(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Input_preprocess/\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300644289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data and basic EDA"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import data with input and target\n",
        "import pandas as pd\n",
        "import json\n",
        "train = pd.read_csv(str(INPUT_DIR)+'/preprocessed.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300644764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "display(train.head())\n",
        "print(train.scored.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300645143
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preproccessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['label'] = train['scored']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300645652
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['label', 'text_parsed']]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300646163
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300646633
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create folds\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "X = train.loc[:, train.columns != \"label\"]\n",
        "y = train.loc[:, train.columns == \"label\"]\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
        "    train.loc[valid_index, \"fold\"] = i\n",
        "    \n",
        "print(train.groupby(\"fold\")[\"label\"].value_counts())\n",
        "train.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300647289
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# establish validation data\n",
        "\n",
        "val = train[train[\"fold\"] == 0]\n",
        "train = train[train[\"fold\"] != 0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300647644
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train[[\"text_parsed\", \"label\"]]\n",
        "valid_df = val[[\"text_parsed\", \"label\"]]\n",
        "\n",
        "print(train_df.shape)\n",
        "print(train_df.label.value_counts())\n",
        "print(valid_df.shape)\n",
        "print(valid_df.label.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300648133
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import datasets\n",
        "\n",
        "#!pip install -q -U peft --no-index --find-links file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Input/\n",
        "#!pip install -q -U accelerate --no-index --find-links file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Input/\n",
        "#!pip install -q -U bitsandbytes --no-index --find-links file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Input/\n",
        "#!pip install -q -U transformers --no-index --find-links file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Input/\n",
        "#!pip install torch\n",
        "\n",
        "%pip install -q -U peft\n",
        "%pip install -q -U accelerate\n",
        "%pip install -q -U bitsandbytes\n",
        "%pip install -q -U transformers\n",
        "%pip install -q -U sentencepiece \n",
        "%pip install torch\n",
        "%pip install datasets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300667322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model with 4bit bnb\n",
        "\n",
        "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "quantized = False\n",
        "if quantized:\n",
        "\n",
        "    peft_config = LoraConfig(\n",
        "        r=64,\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_CLS,\n",
        "        inference_mode=False,\n",
        "        target_modules=[\n",
        "            \"q_proj\",\n",
        "            \"v_proj\"\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    #bnb_config = BitsAndBytesConfig(\n",
        "    #    load_in_8bit=True,\n",
        "    #    bnb_8bit_quant_type=\"nf8\",\n",
        "    #    bnb_8bit_use_double_quant=True,\n",
        "    #    bnb_8bit_compute_dtype=torch.float16\n",
        "    #)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300674419
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, LlamaForSequenceClassification, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300674899
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if quantized:\n",
        "    base_model = LlamaForSequenceClassification.from_pretrained(\n",
        "        TARGET_MODEL,\n",
        "        num_labels=5,\n",
        "        quantization_config=bnb_config,   #TO QUANTIZE\n",
        "        device_map={\"\":0}\n",
        "    )\n",
        "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
        "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "if not quantized:\n",
        "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        TARGET_MODEL,\n",
        "        num_labels=5,\n",
        "        device_map={\"\":0}\n",
        "    )\n",
        "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
        "    base_model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300679073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if quantized:\n",
        "    model = get_peft_model(base_model, peft_config)\n",
        "\n",
        "if not quantized:   \n",
        "    model = base_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300679287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if quantized:\n",
        "    model.print_trainable_parameters()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300679483
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.shape)\n",
        "print(valid_df.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300679689
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.label.value_counts(), valid_df.label.value_counts())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300680202
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets\n",
        "from datasets import Dataset\n",
        "\n",
        "# from pandas\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "valid_ds = Dataset.from_pandas(valid_df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300680644
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples, max_length=1024):   \n",
        "    return tokenizer(examples[\"text_parsed\"], truncation=True, max_length=max_length, padding=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300681065
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\n",
        "valid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300681651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300682129
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(np.array(predictions), axis=1)\n",
        "\n",
        "    unique_classes = np.unique(labels)\n",
        "    class_mae_values = []\n",
        "    \n",
        "    for cls in unique_classes:\n",
        "        cls_indices = np.where(labels == cls)\n",
        "        cls_labels = labels[cls_indices]\n",
        "        cls_predictions = predictions[cls_indices]\n",
        "        \n",
        "        if len(cls_labels) > 0:  # Avoid division by zero\n",
        "            cls_mae = mean_absolute_error(cls_labels, cls_predictions)\n",
        "            class_mae_values.append(cls_mae)\n",
        "    \n",
        "    mean_class_mae = np.mean(class_mae_values) if class_mae_values else None\n",
        "    \n",
        "    return {\n",
        "        \"mean_class_mae\": mean_class_mae,\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300682562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "steps = 25\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    max_grad_norm=0.3,\n",
        "    optim='paged_adamw_32bit',\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=1e-5,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    warmup_ratio=0.1,\n",
        "    eval_steps=steps,\n",
        "    logging_steps=steps,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_ds,\n",
        "    eval_dataset=valid_tokenized_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[early_stopping],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300760493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import rmtree\n",
        "\n",
        "trainer.save_model(output_dir=str(OUTPUT_DIR))\n",
        "\n",
        "for path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n",
        "    if path.is_dir():\n",
        "        rmtree(path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300762552
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del trainer, model, base_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300762747
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cuda cache clear\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300762954
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test loading model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model / tokenizer with 4bit bnb\n",
        "\n",
        "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "quantized = False\n",
        "if quantized:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300763153
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, LlamaForSequenceClassification, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300763450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if quantized:\n",
        "    base_model = LlamaForSequenceClassification.from_pretrained(\n",
        "        TARGET_MODEL,\n",
        "        num_labels=5,\n",
        "        quantization_config=bnb_config,   #TO QUANTIZE\n",
        "        device_map={\"\":0}\n",
        "    )\n",
        "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
        "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "if not quantized:\n",
        "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        TARGET_MODEL,\n",
        "        num_labels=5,\n",
        "        device_map={\"\":0}\n",
        "    )\n",
        "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
        "    base_model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300763745
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if quantized:\n",
        "    model = get_peft_model(base_model, peft_config)\n",
        "\n",
        "if not quantized:   \n",
        "    model = base_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300763948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300764542
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_output = trainer.predict(valid_tokenized_ds)\n",
        "logits = pred_output.predictions\n",
        "logits"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300765269
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = np.argmax(logits, axis=1)\n",
        "\n",
        "probs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300765605
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub = valid_df.copy()\n",
        "sub['predictions'] = probs\n",
        "# sub.to_csv('submission.csv', index=False)\n",
        "sub.head(50)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718300766051
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test for promptflow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "%pip install -q -U peft\n",
        "%pip install -q -U accelerate\n",
        "%pip install -q -U bitsandbytes\n",
        "%pip install -q -U transformers\n",
        "%pip install -q -U sentencepiece \n",
        "%pip install torch\n",
        "%pip install datasets\n",
        "from datasets import Dataset\n",
        "\n",
        "TARGET_MODEL = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Output/\"\n",
        "INPUT_DIR = Path(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/cn1/code/Users/CN/Input_preprocess/\")\n",
        "train = pd.read_csv(str(INPUT_DIR)+'/preprocessed.csv')\n",
        "train['label'] = train['scored']\n",
        "train = train[['label', 'text_parsed']]\n",
        "train_df = train[[\"text_parsed\", \"label\"]]\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "\n",
        "# load model / tokenizer with 4bit bnb\n",
        "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "quantized = False\n",
        "if quantized:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "from transformers import AutoTokenizer, LlamaForSequenceClassification, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "def preprocess_function(examples, max_length=1024):   \n",
        "    return tokenizer(examples[\"text_parsed\"], truncation=True, max_length=max_length, padding=True)\n",
        "train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
        "\n",
        "if quantized:\n",
        "    base_model = LlamaForSequenceClassification.from_pretrained(\n",
        "        TARGET_MODEL,\n",
        "        num_labels=5,\n",
        "        quantization_config=bnb_config,   #TO QUANTIZE\n",
        "        device_map={\"\":0}\n",
        "    )\n",
        "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
        "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "if not quantized:\n",
        "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        TARGET_MODEL,\n",
        "        num_labels=5,\n",
        "        device_map={\"\":0}\n",
        "    )\n",
        "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
        "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "if quantized:\n",
        "    model = get_peft_model(base_model, peft_config)\n",
        "\n",
        "if not quantized:   \n",
        "    model = base_model\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "pred_output = trainer.predict(train_tokenized_ds)\n",
        "logits = pred_output.predictions\n",
        "\n",
        "probs = np.argmax(logits, axis=1)\n",
        "\n",
        "sub = train_df.copy()\n",
        "sub['predictions'] = probs\n",
        "sub.head(50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: torch in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (4.11.0)\nRequirement already satisfied: sympy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2023.6.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: datasets in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (3.12.2)\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (1.25.0)\nRequirement already satisfied: pyarrow>=12.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (12.0.1)\nRequirement already satisfied: pyarrow-hotfix in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (4.65.0)\nRequirement already satisfied: xxhash in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (0.23.3)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (23.0)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nMap: 100%|██████████| 593/593 [00:00<00:00, 1514.09 examples/s]\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "                                          text_parsed  label  predictions\n0                             Starting OK, go for it.      4            1\n1                                 Alright, thank you.      0            0\n2                                          Thank you.      0            0\n3   So this general path thing just allows us to m...      4            4\n4                              Why is that important?      4            4\n5                                     Context is key.      0            0\n6   When using any type of generative AI, it's onl...      1            1\n7   So in this context, what we wanted to understa...      3            2\n8   I took these based off of the objectives you p...      1            1\n9                                   Nicole and Jerry.      0            0\n10  From there, she wants to understand who the au...      1            1\n11  So that was also something that we kind of gen...      3            4\n12  LinkedIn and Instagram is what was provided an...      1            2\n13  So based off of this, I didn't really have a n...      0            1\n14                                               Umm.      0            0\n15  So what I did is I actually took your values c...      1            1\n16           John to create a new branding guideline.      0            1\n17  So if there's a branding guideline you already...      1            1\n18                                                OK.      0            0\n19  But if you don't have one, it's also something...      0            1\n20  So if you get to Vivian at the end and we're t...      4            4\n21  Because that's one of the buildings like brand...      0            0\n22                                               But.      0            0\n23  All you have to do is really provide the hex c...      0            1\n24  So she pretty much just outlines the key areas...      0            0\n25  When sort of that branding outline, because th...      0            0\n26  And then from there, it really just she's buil...      0            0\n27    So what are we trying to do and outlining that?      4            4\n28                                      Ohboy chunky.      0            0\n29  The only thing this is really there is for you...      1            1\n30                    So we call this self prompting.      1            1\n31  What she's doing is outlining what you need to...      0            0\n32  Typically this she will skip to Cassie because...      0            1\n33  But there is another agent called Marcus that ...      1            1\n34  And what I wanted him to do was specifically t...      1            1\n35  So we provided in that building, he outlined s...      1            1\n36                             He also does research.      0            0\n37  So as he's analyzing and outlining these, we s...      0            0\n38  So very quickly I went from hey, this is the f...      0            0\n39  I would like to create a strategy around that ...      1            1\n40  Sophie outlined strategy, so if you kind of lo...      2            2\n41                  So she's gonna lay out one month.      0            0\n42  You can do up to 812 whatever amount of weeks ...      1            1\n43                                               Umm.      0            0\n44                                       That's fine.      0            0\n45  I'm going to go after this platform and the co...      3            2\n46                                              Yeah.      0            0\n47  So what I like to do a lot of times is I like ...      2            2\n48                                            Really.      0            0\n49  O do you create different pages for each build...      4            4",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_parsed</th>\n      <th>label</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Starting OK, go for it.</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alright, thank you.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thank you.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>So this general path thing just allows us to m...</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Why is that important?</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Context is key.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>When using any type of generative AI, it's onl...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>So in this context, what we wanted to understa...</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I took these based off of the objectives you p...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Nicole and Jerry.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>From there, she wants to understand who the au...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>So that was also something that we kind of gen...</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>LinkedIn and Instagram is what was provided an...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>So based off of this, I didn't really have a n...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Umm.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>So what I did is I actually took your values c...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>John to create a new branding guideline.</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>So if there's a branding guideline you already...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>OK.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>But if you don't have one, it's also something...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>So if you get to Vivian at the end and we're t...</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Because that's one of the buildings like brand...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>But.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>All you have to do is really provide the hex c...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>So she pretty much just outlines the key areas...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>When sort of that branding outline, because th...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>And then from there, it really just she's buil...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>So what are we trying to do and outlining that?</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Ohboy chunky.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>The only thing this is really there is for you...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>So we call this self prompting.</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>What she's doing is outlining what you need to...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Typically this she will skip to Cassie because...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>But there is another agent called Marcus that ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>And what I wanted him to do was specifically t...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>So we provided in that building, he outlined s...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>He also does research.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>So as he's analyzing and outlining these, we s...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>So very quickly I went from hey, this is the f...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>I would like to create a strategy around that ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>Sophie outlined strategy, so if you kind of lo...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>So she's gonna lay out one month.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>You can do up to 812 whatever amount of weeks ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Umm.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>That's fine.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>I'm going to go after this platform and the co...</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Yeah.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>So what I like to do a lot of times is I like ...</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Really.</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>O do you create different pages for each build...</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1718302520490
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}