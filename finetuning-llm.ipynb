{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import annotations\n\n#TARGET_MODEL = \"mistralai/Mistral-7B-v0.1\"\n#TARGET_MODEL = \"HuggingFaceH4/zephyr-7b-alpha\"\nTARGET_MODEL = \"microsoft/deberta-v3-large\"\n\nDEBUG = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% Directory settings\n\n# ====================================================\n# Directory settings\n# ====================================================\nfrom pathlib import Path\n\nOUTPUT_DIR = Path(\"./\")\nOUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n\nINPUT_DIR = Path(\"../input/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n#Import train\n\n#train = \n#print(train.label.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\ndisplay(train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nX = train.loc[:, train.columns != \"label\"]\ny = train.loc[:, train.columns == \"label\"]\n\nfor i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n    train.loc[valid_index, \"fold\"] = i\n    \nprint(train.groupby(\"fold\")[\"label\"].value_counts())\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns=[\"source\", \"prompt_name\"],inplace=True)\n\nprint(train.shape)\ndisplay(train.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"fold\"] = train[\"fold\"].astype(int)\nprint(train.fold.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold0 as valid\nval = train[train[\"fold\"] == 0]\ntrain = train[train[\"fold\"] != 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train.head(3))\ndisplay(val.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train[[\"text\", \"label\"]]\nvalid_df = val[[\"text\", \"label\"]]\nprint(train_df.shape)\nprint(train_df.label.value_counts())\nprint(valid_df.shape)\nprint(valid_df.label.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/code/hotchpotch/llm-detect-pip\n\n!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U accelerate --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model with 4bit bnb\n\nfrom peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\nfrom transformers import BitsAndBytesConfig\nimport torch\n\npeft_config = LoraConfig(\n    r=64,\n    lora_alpha=16,\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS,\n    inference_mode=False,\n    target_modules=[\n        \"q_proj\",\n        \"v_proj\"\n    ],\n)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n#bnb_config = BitsAndBytesConfig(\n#    load_in_8bit=True,\n#    bnb_8bit_quant_type=\"nf8\",\n#    bnb_8bit_use_double_quant=True,\n#    bnb_8bit_compute_dtype=torch.float16\n#)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, LlamaForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = LlamaForSequenceClassification.from_pretrained(\n    TARGET_MODEL,\n    num_labels=2,\n    quantization_config=bnb_config,   #TO QUANTIZE\n    device_map={\"\":0}\n)\nbase_model.config.pretraining_tp = 1 # 1 is 7b\nbase_model.config.pad_token_id = tokenizer.pad_token_id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(base_model, peft_config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(valid_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.label.value_counts(), valid_df.label.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets\nfrom datasets import Dataset\n\n# from pandas\ntrain_ds = Dataset.from_pandas(train_df)\nvalid_ds = Dataset.from_pandas(valid_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples, max_length=512):   \n    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length, padding=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\nvalid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    accuracy_val = accuracy_score(labels, predictions)\n    roc_auc_val = roc_auc_score(labels, predictions)\n    \n    return {\n        \"accuracy\": accuracy_val,\n        \"roc_auc\": roc_auc_val,\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom transformers import EarlyStoppingCallback\n\nsteps = 5 if DEBUG else 20\n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    learning_rate=5e-5,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=16,\n    max_grad_norm=0.3,\n    optim='paged_adamw_32bit',\n    lr_scheduler_type=\"cosine\",\n    num_train_epochs=1,\n    weight_decay=0.01,\n    evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    warmup_steps=steps,\n    eval_steps=steps,\n    logging_steps=steps,\n    report_to='none'\n)\n\nearly_stopping = EarlyStoppingCallback(early_stopping_patience=2)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized_ds,\n    eval_dataset=valid_tokenized_ds,\n    tokenizer=tokenizer,\n    callbacks=[early_stopping],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shutil import rmtree\n\ntrainer.save_model(output_dir=str(OUTPUT_DIR))\n\nfor path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n    if path.is_dir():\n        rmtree(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del trainer, model, base_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cuda cache clear\nimport torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model / tokenizer with 4bit bnb\n\nfrom peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\nfrom transformers import BitsAndBytesConfig\nimport torch\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, LlamaForSequenceClassification\n\nbase_model = LlamaForSequenceClassification.from_pretrained(\n    TARGET_MODEL,\n    num_labels=2,\n    quantization_config=bnb_config,\n    device_map={\"\":0}\n)\nbase_model.config.pretraining_tp = 1 # 1 is 7b\nbase_model.config.pad_token_id = tokenizer.pad_token_id\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = PeftModel.from_pretrained(base_model, str(OUTPUT_DIR))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_output = trainer.predict(valid_tokenized_ds)\nlogits = pred_output.predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = pred_output.predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df.label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy.special import expit as sigmoid\nimport numpy as np\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))  \nprobs = sigmoid(logits[:, 1])\nprobs.shape, probs[0:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['id'] = valid_df['id']\nsub['generated'] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -alh /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}